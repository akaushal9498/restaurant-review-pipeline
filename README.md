# restaurant-review-pipeline

# ğŸ½ï¸ Restaurant Review Pipeline

This project provides a complete **data pipeline** for processing both **batch and streaming restaurant review data**. It is divided into two main components:

- **Batch processing** for Swiggy reviews  
- **Streaming processing** for Amazon reviews

---

## ğŸ“ Project Structure

restaurant-review-pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ swiggy_batch_etl.py          # Airflow DAG for batch processing
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.json                     # Sample data file
â”‚   â””â”€â”€ database.sqlite               # SQLite database file
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ data/                         # Data directory
â”‚   â”œâ”€â”€ amazon_review_stream.py       # Amazon review stream processor
â”‚   â”œâ”€â”€ constants.py                  # Project constants
â”‚   â”œâ”€â”€ helper_flatten.py             # Helper for flattening data
â”‚   â”œâ”€â”€ ingest_amazon_stream.py       # Amazon review ingestion
â”‚   â”œâ”€â”€ ingest_swiggy.py              # Swiggy review ingestion
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ jar_files/
â”‚   â””â”€â”€ sqlite-jdbc-3.49.1.0.jar      # JDBC driver for SQLite
â”œâ”€â”€ warehouse_loader/                 # Data warehouse loading scripts
â”œâ”€â”€ README.md                         
â””â”€â”€ requirements.txt                  # Python dependencies

---

## ğŸ¬ Recording Links

- **Batch (Swiggy)**: [Watch here](https://drive.google.com/file/d/1ORKnLmGTc9T8KMrsyCFSov0cimUk7UH5/view?usp=sharing)  
- **Streaming (Amazon)**: [Watch here](https://drive.google.com/file/d/1-3bangBOIj-sr0g0ZKTVKbQdn0dxyvXE/view?usp=sharing)

---

## ğŸ“¦ Batch Processing: Swiggy Reviews

### ğŸ“Œ Description

The batch pipeline:
- Flattens nested Swiggy review JSON
- Ingests the processed data
- Loads it into **Amazon Redshift**

### â–¶ï¸ How to Run

1. Ensure **Apache Airflow** is installed and configured.
2. Place `swiggy_batch_etl.py` in your Airflow DAGs directory.
3. Airflow will auto-detect the DAG.
4. Trigger the DAG manually or let it run as per schedule.

### ğŸ§© Dependencies

- Apache Airflow
- Python packages listed in `requirements.txt`

---

## ğŸ” Streaming Processing: Amazon Reviews

### ğŸ“Œ Description

The streaming pipeline:
- Simulates a stream of Amazon restaurant reviews
- Processes the stream in 5-second intervals
- Ingests the reviews into the system

### â–¶ï¸ How to Run

**Terminal 1: Start the stream**
python ingestion/ingest_amazon_stream.py

**Terminal 2: Start the ingestion
The ingestion script reads new data every 5 seconds.


ğŸ§© Dependencies
Python 3.x

Python packages listed in requirements.txt


ğŸ“¦ Requirements
Install all required Python packages:

pip install -r requirements.txt


âœ… Assumptions
Swiggy batch data is available in the correct format and path

Amazon streaming data is consistently emitted by the simulator

Redshift cluster is accessible and properly configured

Airflow is fully operational

Your Python environment can read/write files and connect to databases

ğŸ§° Troubleshooting
âŒ Batch failure? â†’ Check Airflow logs in the UI

ğŸ’¤ Streaming stopped? â†’ Ensure both simulator and ingestion scripts are running

ğŸ”‘ Database errors? â†’ Double-check SQLite and Redshift credentials and paths